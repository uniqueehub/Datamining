# -*- coding: utf-8 -*-
"""DataMiningAssignment6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VrdjN8QJDQBQeEamdZ_23AzZjLKya1n8
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('Iris.csv')
print(df)

df.info()

df.isnull().sum()

print(f"The dimmension of Dataset: {df.shape}")

df.describe()
#The description shows we have data with super low std (Standard Deviation)
#the range of the SepalLengthCm is: 4.300000 - 7.900000
#the range of the SepalWidthCm is : 2.000000 - 4.400000
#the range of the PetalLengthCm is: 1.000000 - 6.900000
#the range of the PetalWidthCm is : 0.100000 - 2.500000

df.groupby("Species").size()   #Since we predicting the Species of a given flower, let's examine what's the Species distribution for this dataset.

#Distribution visualization
sns.set_style("whitegrid")  # Set the style

# Define your custom color palette
custom_palette = ["Orange", "lightblue", "yellow"]  # Example colors, you can specify your own colors

# Plotting
plt.figure(figsize=(8, 6))
sns.countplot(x='Species', data=df, palette=custom_palette)  # Use the custom color palette
plt.title('Flower Species Distribution')
plt.ylabel('Count', size=12)
plt.xlabel('Species', size=12)
plt.show()

sns.set_style("whitegrid")  # Set the style

# Define your custom color palette
custom_palette = ["Orange", "lightblue", "yellow"]  # Example colors, you can specify your own colors

# Plotting
plt.figure(figsize=(10, 8))
sns.boxplot(data=df, orient="v", palette=custom_palette)  # Use the custom color palette
plt.title("Box and Whisker plot for each attribute")
plt.show()

sns.set_style("whitegrid")  # Set the style

# Define your custom color palette
custom_palette = ["#FF5733", "#33FF57", "#3366FF"]  # Example colors, you can specify your own colors

# Plotting
plt.figure(figsize=(10,8))
sns.histplot(data=df, kde=False, palette=custom_palette)
plt.title('Histogram for each attribute')
plt.show()

df.hist()
plt.show()

#Data Modeling .Classification Problem: Our goal is to predict the follow "Species" with given features: SepalLengthCm, SepalWidthCm, PetalLengthCm, and PetalWidthCm.
#Train-Test Split We will use Sklearn to split the arrays or matrices into random train and test subsets for training and testing machine learning model.

#Our X will be the feature of the flowers and Y will be the label of the flowers.
from sklearn.model_selection import train_test_split
# we will split data to 80% training data and 20% testing data
# with random seed of 10
X = df.drop(['Species'], axis=1)
y = df['Species']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)

print(f"X Train Shape: {X_train.shape}")
print(f"X Test Shape: {X_test.shape}")
print(f"Y Train Shape: {y_train.shape}")
print(f"Y Test Shape: {y_test.shape}")

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

models = []

# Linear Model
models.append(("LR", LogisticRegression(solver='liblinear', multi_class='auto')))
models.append(('LDA', LinearDiscriminantAnalysis()))

# Nonlinear models
models.append(('CART', DecisionTreeClassifier()))
models.append(('KNN', KNeighborsClassifier()))
models.append(('GNB', GaussianNB()))
models.append(("SVC", SVC()))

# Add Random Forest
models.append(("RandomForest", RandomForestClassifier()))

print(models)

print("Model Accuracy: ")
all_results = []  # List to store all accuracy results

for name, model in models:
    # 10 fold cross validation to evaluate model
    kfold = KFold(n_splits=10, shuffle=True, random_state=7)
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')
    res = f"{name}: accuracy={cv_results.mean():.4f} std={cv_results.std():.4f}"
    print(res)
    # Store the accuracy results
    for result in cv_results:
        all_results.append({'Model': name, 'Accuracy': result})

# Create a DataFrame from the accuracy results
df_accuracy = pd.DataFrame(all_results)

import matplotlib.pyplot as plt

# Define the classification techniques and their corresponding accuracies and standard deviations
classifiers = ['LR', 'LDA', 'CART', 'KNN', 'GNB', 'SVC','RFR']
accuracies = [0.9583, 0.9750, 0.9500, 0.9833, 0.9667, 0.9833,0.9667]
std_devs = [0.0559, 0.0382, 0.0764, 0.0333, 0.0408, 0.0333,0.0408]

# Plotting
plt.figure(figsize=(10, 6))

# Plot the bars for accuracies
plt.bar(classifiers, accuracies, color='skyblue', label='Accuracy')

# Plot the error bars for standard deviations
plt.errorbar(classifiers, accuracies, yerr=std_devs, fmt='o', color='black', label='Std Dev', capsize=5)

# Add labels and title
plt.xlabel('Classification Techniques')
plt.ylabel('Accuracy')
plt.title('Comparison of Classification Techniques')
plt.legend()

# Show plot
plt.tight_layout()
plt.show()

models = []
models.append(("KNN", KNeighborsClassifier()))
models.append(('LDA', LinearDiscriminantAnalysis()))
models.append(("SVC", SVC()))

def test_model(model):
    model.fit(X_train, y_train)  # train the whole training set
    predictions = model.predict(X_test)  # predict on test set

    # Output model testing results
    print("Accuracy:", accuracy_score(y_test, predictions))

    # Compute confusion matrix
    cm = confusion_matrix(y_test, predictions)

    # Plot confusion matrix
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)
    disp.plot(cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.show()

    # Print classification report
    print("Classification Report:")
    print(classification_report(y_test, predictions))

# predict values with our test set
for name, model in models:
    print("----------------")
    print("Testing", name)
    test_model(model)

#The highest testing accuracy is 0.97 from Linear Discriminant Analysis (LDA).
#The LDA's confustion matrix has the highest diagonal values indicated that LDA predicted the
# class type better than the other 2 models.
#From above confusion matrix and classification report, the LDA model
#is the best model for our classification problem.